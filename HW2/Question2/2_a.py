# -*- coding: utf-8 -*-
"""2_a.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qQml9KIXluNmR7xUQNblQMPFeYiTXZKi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")
np.random.seed(100)

data_train = pd.read_csv("bank-note/train.csv", header=None)
data_test = pd.read_csv("bank-note/test.csv", header=None)
X = data_train.iloc[:,:4]
Y = data_train.iloc[:,-1]
X_test = data_test.iloc[:,:4]
Y_test = data_test.iloc[:,-1]

def logistic_regression_newton_raphson(X, t):
    w = np.zeros(X.shape[1])
    alpha = 1
    max_iter = 100
    epsilon = 1e-5
    lambd = 1
    I = np.identity(X.shape[1])
    for i in range(max_iter):
        z = np.dot(X, w)
        y= 1.0 / (1.0 + np.exp(-z))
        grad = np.dot(X.T, y - t) 
        H = np.dot(X.T * y * (1 - y), X) + I
        w_new = w - alpha * np.dot(np.linalg.inv(H), grad)
        if np.linalg.norm(w_new - w) < epsilon:
            break
        w = w_new
    return w
def eval(data, labels, weights):
    c = 0
    for i in range(data.shape[0]):
        z = np.dot(np.array(data.iloc[i]), weights)
        y= 1.0 / (1.0 + np.exp(-z))
        if y>=0.5:
          if 1 == labels.iloc[i]:
              c+=1
        else:
          if 0 == labels.iloc[i]:
              c+=1
    return c

weights = logistic_regression_newton_raphson(X,Y)
print("With Initializing the weights to be zero: ")
print("The converged weights are : ",weights)
print("Train Accuracy ",eval(X, Y, weights)/len(Y))
print("Test Accuracy ",eval(X_test, Y_test, weights)/len(Y_test))

def logistic_regression_newton_raphson(X, t):
    w = np.random.normal(0,1,size=X.shape[1])
    alpha = 1
    max_iter = 100
    epsilon = 1e-5
    lambd = 1
    I = np.identity(X.shape[1])
    for i in range(max_iter):
        z = np.dot(X, w)
        y= 1.0 / (1.0 + np.exp(-z))
        grad = np.dot(X.T, y - t) 
        H = np.dot(X.T * y * (1 - y), X) +I
        # if np.linalg.det(H)!=0:
        w_new = w - alpha * np.dot(np.linalg.inv(H), grad)
        if np.linalg.norm(w_new - w) < epsilon:
            break
        w = w_new
    return w
def eval(data, labels, weights):
    c = 0
    for i in range(data.shape[0]):
        z = np.dot(np.array(data.iloc[i]), weights)
        y= 1.0 / (1.0 + np.exp(-z))
        if y>=0.5:
          if 1 == labels.iloc[i]:
              c+=1
        else:
          if 0 == labels.iloc[i]:
              c+=1
    return c

weights = logistic_regression_newton_raphson(X,Y)
print("With Initializing the weights to be random normal: ")
print("The converged weights are : ",weights)
print("Train Accuracy ",eval(X, Y, weights)/len(Y))
print("Test Accuracy ",eval(X_test, Y_test, weights)/len(Y_test))

